{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJYKpAK5t53c",
        "outputId": "bab9375d-23d9-4c6c-f047-9d8264f02b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 8000\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib.request  # import the correct submodule\n",
        "\n",
        "\n",
        "def download_and_load_file(file_path: str, url: str | None = None):\n",
        "    \"\"\"\n",
        "    If file_path doesn't exist and url is provided, download it.\n",
        "    Then load and return:\n",
        "      - list of objects for .jsonl\n",
        "      - parsed JSON for .json\n",
        "    \"\"\"\n",
        "    # Download only if missing and a URL is provided\n",
        "    if not os.path.exists(file_path):\n",
        "        if not url:\n",
        "            raise FileNotFoundError(f\"{file_path} not found and no URL provided.\")\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(text_data)\n",
        "\n",
        "    # Load JSON or JSONL\n",
        "    if file_path.lower().endswith(\".jsonl\"):\n",
        "        data = []\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line:  # skip blank lines\n",
        "                    data.append(json.loads(line))\n",
        "    else:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# Use it\n",
        "file_path = \"assistant_instruction_simple.jsonl\"\n",
        "data = download_and_load_file(file_path)  # pass url=... if you want auto-download\n",
        "print(\"Number of entries:\", len(data))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ],
      "metadata": {
        "id": "gY-fyvGzuEoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ],
      "metadata": {
        "id": "XpIoZOgPuElq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2.1 -> 2.2\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "qZablYV6uEjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "eIEFcHJkuEgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W99k9oBOuEeE",
        "outputId": "a51cef1b-a655-4351-aad2-26a2f09b969a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=768\n",
        ")"
      ],
      "metadata": {
        "id": "DHjz564yuEbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2mzll2GuEYr",
        "outputId": "9ceec914-278a-4125-c0fd-8e78de5ca6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "id": "KpzxXeKYuRSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "from previous_chapters import GPTModel, load_weights_into_gpt\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnCW3EN8uRP_",
        "outputId": "c24d2f6e-bdd7-4ace-e826-843f677b107a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from previous_chapters import (\n",
        "    generate,\n",
        "    text_to_token_ids,\n",
        "    token_ids_to_text\n",
        ")\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ],
      "metadata": {
        "id": "ZXqIr1N4uRNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_text = (\n",
        "    generated_text[len(input_text):]\n",
        "    .replace(\"### Response:\", \"\")\n",
        "    .strip()\n",
        ")\n",
        "print(response_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL7wlMh3uRK5",
        "outputId": "20f118df-e307-428b-a221-a5172909d02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symptoms: nausea, vomiting, diarrhea, and abdominal pain.\n",
            "\n",
            "\n",
            "\n",
            "Symptoms: nausea, vomiting, diarrhea\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from previous_chapters import (\n",
        "    calc_loss_loader,\n",
        "    train_model_simple\n",
        ")\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "xFNhgvT5uRIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TpixvBDuavN",
        "outputId": "8f6e1863-d2ac-47e8-bfec-6b324c7bd3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 3.316, Val loss 3.294\n",
            "Ep 1 (Step 000005): Train loss 1.242, Val loss 1.267\n",
            "Ep 1 (Step 000010): Train loss 0.386, Val loss 0.407\n",
            "Ep 1 (Step 000015): Train loss 0.304, Val loss 0.316\n",
            "Ep 1 (Step 000020): Train loss 0.295, Val loss 0.272\n",
            "Ep 1 (Step 000025): Train loss 0.235, Val loss 0.253\n",
            "Ep 1 (Step 000030): Train loss 0.228, Val loss 0.230\n",
            "Ep 1 (Step 000035): Train loss 0.240, Val loss 0.221\n",
            "Ep 1 (Step 000040): Train loss 0.227, Val loss 0.212\n",
            "Ep 1 (Step 000045): Train loss 0.214, Val loss 0.206\n",
            "Ep 1 (Step 000050): Train loss 0.196, Val loss 0.197\n",
            "Ep 1 (Step 000055): Train loss 0.204, Val loss 0.188\n",
            "Ep 1 (Step 000060): Train loss 0.171, Val loss 0.182\n",
            "Ep 1 (Step 000065): Train loss 0.176, Val loss 0.181\n",
            "Ep 1 (Step 000070): Train loss 0.177, Val loss 0.175\n",
            "Ep 1 (Step 000075): Train loss 0.174, Val loss 0.171\n",
            "Ep 1 (Step 000080): Train loss 0.168, Val loss 0.174\n",
            "Ep 1 (Step 000085): Train loss 0.152, Val loss 0.168\n",
            "Ep 1 (Step 000090): Train loss 0.163, Val loss 0.160\n",
            "Ep 1 (Step 000095): Train loss 0.160, Val loss 0.163\n",
            "Ep 1 (Step 000100): Train loss 0.143, Val loss 0.153\n",
            "Ep 1 (Step 000105): Train loss 0.150, Val loss 0.151\n",
            "Ep 1 (Step 000110): Train loss 0.140, Val loss 0.148\n",
            "Ep 1 (Step 000115): Train loss 0.145, Val loss 0.151\n",
            "Ep 1 (Step 000120): Train loss 0.144, Val loss 0.147\n",
            "Ep 1 (Step 000125): Train loss 0.140, Val loss 0.146\n",
            "Ep 1 (Step 000130): Train loss 0.134, Val loss 0.142\n",
            "Ep 1 (Step 000135): Train loss 0.132, Val loss 0.138\n",
            "Ep 1 (Step 000140): Train loss 0.137, Val loss 0.139\n",
            "Ep 1 (Step 000145): Train loss 0.138, Val loss 0.137\n",
            "Ep 1 (Step 000150): Train loss 0.134, Val loss 0.140\n",
            "Ep 1 (Step 000155): Train loss 0.134, Val loss 0.141\n",
            "Ep 1 (Step 000160): Train loss 0.131, Val loss 0.137\n",
            "Ep 1 (Step 000165): Train loss 0.134, Val loss 0.136\n",
            "Ep 1 (Step 000170): Train loss 0.132, Val loss 0.139\n",
            "Ep 1 (Step 000175): Train loss 0.130, Val loss 0.140\n",
            "Ep 1 (Step 000180): Train loss 0.136, Val loss 0.131\n",
            "Ep 1 (Step 000185): Train loss 0.126, Val loss 0.130\n",
            "Ep 1 (Step 000190): Train loss 0.127, Val loss 0.130\n",
            "Ep 1 (Step 000195): Train loss 0.128, Val loss 0.131\n",
            "Ep 1 (Step 000200): Train loss 0.129, Val loss 0.133\n",
            "Ep 1 (Step 000205): Train loss 0.126, Val loss 0.133\n",
            "Ep 1 (Step 000210): Train loss 0.126, Val loss 0.132\n",
            "Ep 1 (Step 000215): Train loss 0.126, Val loss 0.131\n",
            "Ep 1 (Step 000220): Train loss 0.128, Val loss 0.132\n",
            "Ep 1 (Step 000225): Train loss 0.131, Val loss 0.132\n",
            "Ep 1 (Step 000230): Train loss 0.126, Val loss 0.130\n",
            "Ep 1 (Step 000235): Train loss 0.128, Val loss 0.131\n",
            "Ep 1 (Step 000240): Train loss 0.123, Val loss 0.130\n",
            "Ep 1 (Step 000245): Train loss 0.131, Val loss 0.129\n",
            "Ep 1 (Step 000250): Train loss 0.132, Val loss 0.133\n",
            "Ep 1 (Step 000255): Train loss 0.124, Val loss 0.128\n",
            "Ep 1 (Step 000260): Train loss 0.129, Val loss 0.129\n",
            "Ep 1 (Step 000265): Train loss 0.127, Val loss 0.128\n",
            "Ep 1 (Step 000270): Train loss 0.127, Val loss 0.129\n",
            "Ep 1 (Step 000275): Train loss 0.131, Val loss 0.133\n",
            "Ep 1 (Step 000280): Train loss 0.119, Val loss 0.130\n",
            "Ep 1 (Step 000285): Train loss 0.125, Val loss 0.129\n",
            "Ep 1 (Step 000290): Train loss 0.130, Val loss 0.131\n",
            "Ep 1 (Step 000295): Train loss 0.125, Val loss 0.129\n",
            "Ep 1 (Step 000300): Train loss 0.124, Val loss 0.128\n",
            "Ep 1 (Step 000305): Train loss 0.129, Val loss 0.129\n",
            "Ep 1 (Step 000310): Train loss 0.123, Val loss 0.123\n",
            "Ep 1 (Step 000315): Train loss 0.121, Val loss 0.125\n",
            "Ep 1 (Step 000320): Train loss 0.132, Val loss 0.127\n",
            "Ep 1 (Step 000325): Train loss 0.123, Val loss 0.128\n",
            "Ep 1 (Step 000330): Train loss 0.123, Val loss 0.125\n",
            "Ep 1 (Step 000335): Train loss 0.123, Val loss 0.125\n",
            "Ep 1 (Step 000340): Train loss 0.124, Val loss 0.127\n",
            "Ep 1 (Step 000345): Train loss 0.124, Val loss 0.127\n",
            "Ep 1 (Step 000350): Train loss 0.124, Val loss 0.126\n",
            "Ep 1 (Step 000355): Train loss 0.128, Val loss 0.126\n",
            "Ep 1 (Step 000360): Train loss 0.126, Val loss 0.126\n",
            "Ep 1 (Step 000365): Train loss 0.121, Val loss 0.123\n",
            "Ep 1 (Step 000370): Train loss 0.123, Val loss 0.123\n",
            "Ep 1 (Step 000375): Train loss 0.122, Val loss 0.126\n",
            "Ep 1 (Step 000380): Train loss 0.127, Val loss 0.125\n",
            "Ep 1 (Step 000385): Train loss 0.122, Val loss 0.125\n",
            "Ep 1 (Step 000390): Train loss 0.123, Val loss 0.125\n",
            "Ep 1 (Step 000395): Train loss 0.126, Val loss 0.125\n",
            "Ep 1 (Step 000400): Train loss 0.123, Val loss 0.123\n",
            "Ep 1 (Step 000405): Train loss 0.123, Val loss 0.125\n",
            "Ep 1 (Step 000410): Train loss 0.119, Val loss 0.124\n",
            "Ep 1 (Step 000415): Train loss 0.121, Val loss 0.125\n",
            "Ep 1 (Step 000420): Train loss 0.121, Val loss 0.124\n",
            "Ep 1 (Step 000425): Train loss 0.125, Val loss 0.124\n",
            "Ep 1 (Step 000430): Train loss 0.123, Val loss 0.127\n",
            "Ep 1 (Step 000435): Train loss 0.125, Val loss 0.130\n",
            "Ep 1 (Step 000440): Train loss 0.128, Val loss 0.128\n",
            "Ep 1 (Step 000445): Train loss 0.122, Val loss 0.127\n",
            "Ep 1 (Step 000450): Train loss 0.123, Val loss 0.125\n",
            "Ep 1 (Step 000455): Train loss 0.123, Val loss 0.126\n",
            "Ep 1 (Step 000460): Train loss 0.124, Val loss 0.127\n",
            "Ep 1 (Step 000465): Train loss 0.121, Val loss 0.124\n",
            "Ep 1 (Step 000470): Train loss 0.122, Val loss 0.125\n",
            "Ep 1 (Step 000475): Train loss 0.125, Val loss 0.127\n",
            "Ep 1 (Step 000480): Train loss 0.126, Val loss 0.127\n",
            "Ep 1 (Step 000485): Train loss 0.123, Val loss 0.124\n",
            "Ep 1 (Step 000490): Train loss 0.121, Val loss 0.124\n",
            "Ep 1 (Step 000495): Train loss 0.120, Val loss 0.125\n",
            "Ep 1 (Step 000500): Train loss 0.127, Val loss 0.127\n",
            "Ep 1 (Step 000505): Train loss 0.119, Val loss 0.128\n",
            "Ep 1 (Step 000510): Train loss 0.124, Val loss 0.128\n",
            "Ep 1 (Step 000515): Train loss 0.126, Val loss 0.128\n",
            "Ep 1 (Step 000520): Train loss 0.121, Val loss 0.127\n",
            "Ep 1 (Step 000525): Train loss 0.122, Val loss 0.127\n",
            "Ep 1 (Step 000530): Train loss 0.119, Val loss 0.124\n",
            "Ep 1 (Step 000535): Train loss 0.123, Val loss 0.124\n",
            "Ep 1 (Step 000540): Train loss 0.126, Val loss 0.130\n",
            "Ep 1 (Step 000545): Train loss 0.123, Val loss 0.128\n",
            "Ep 1 (Step 000550): Train loss 0.120, Val loss 0.125\n",
            "Ep 1 (Step 000555): Train loss 0.123, Val loss 0.125\n",
            "Ep 1 (Step 000560): Train loss 0.121, Val loss 0.125\n",
            "Ep 1 (Step 000565): Train loss 0.121, Val loss 0.126\n",
            "Ep 1 (Step 000570): Train loss 0.120, Val loss 0.127\n",
            "Ep 1 (Step 000575): Train loss 0.124, Val loss 0.128\n",
            "Ep 1 (Step 000580): Train loss 0.120, Val loss 0.127\n",
            "Ep 1 (Step 000585): Train loss 0.123, Val loss 0.127\n",
            "Ep 1 (Step 000590): Train loss 0.121, Val loss 0.125\n",
            "Ep 1 (Step 000595): Train loss 0.122, Val loss 0.125\n",
            "Ep 1 (Step 000600): Train loss 0.125, Val loss 0.122\n",
            "Ep 1 (Step 000605): Train loss 0.123, Val loss 0.123\n",
            "Ep 1 (Step 000610): Train loss 0.123, Val loss 0.123\n",
            "Ep 1 (Step 000615): Train loss 0.120, Val loss 0.123\n",
            "Ep 1 (Step 000620): Train loss 0.124, Val loss 0.125\n",
            "Ep 1 (Step 000625): Train loss 0.125, Val loss 0.126\n",
            "Ep 1 (Step 000630): Train loss 0.122, Val loss 0.125\n",
            "Ep 1 (Step 000635): Train loss 0.118, Val loss 0.124\n",
            "Ep 1 (Step 000640): Train loss 0.122, Val loss 0.124\n",
            "Ep 1 (Step 000645): Train loss 0.118, Val loss 0.122\n",
            "Ep 1 (Step 000650): Train loss 0.124, Val loss 0.121\n",
            "Ep 1 (Step 000655): Train loss 0.121, Val loss 0.126\n",
            "Ep 1 (Step 000660): Train loss 0.123, Val loss 0.127\n",
            "Ep 1 (Step 000665): Train loss 0.122, Val loss 0.128\n",
            "Ep 1 (Step 000670): Train loss 0.123, Val loss 0.128\n",
            "Ep 1 (Step 000675): Train loss 0.121, Val loss 0.127\n",
            "Ep 1 (Step 000680): Train loss 0.120, Val loss 0.127\n",
            "Ep 1 (Step 000685): Train loss 0.121, Val loss 0.127\n",
            "Ep 1 (Step 000690): Train loss 0.123, Val loss 0.125\n",
            "Ep 1 (Step 000695): Train loss 0.123, Val loss 0.125\n",
            "Ep 1 (Step 000700): Train loss 0.124, Val loss 0.125\n",
            "Ep 1 (Step 000705): Train loss 0.125, Val loss 0.124\n",
            "Ep 1 (Step 000710): Train loss 0.121, Val loss 0.124\n",
            "Ep 1 (Step 000715): Train loss 0.122, Val loss 0.126\n",
            "Ep 1 (Step 000720): Train loss 0.122, Val loss 0.125\n",
            "Ep 1 (Step 000725): Train loss 0.121, Val loss 0.124\n",
            "Ep 1 (Step 000730): Train loss 0.128, Val loss 0.126\n",
            "Ep 1 (Step 000735): Train loss 0.121, Val loss 0.125\n",
            "Ep 1 (Step 000740): Train loss 0.122, Val loss 0.124\n",
            "Ep 1 (Step 000745): Train loss 0.122, Val loss 0.122\n",
            "Ep 1 (Step 000750): Train loss 0.119, Val loss 0.123\n",
            "Ep 1 (Step 000755): Train loss 0.118, Val loss 0.123\n",
            "Ep 1 (Step 000760): Train loss 0.120, Val loss 0.123\n",
            "Ep 1 (Step 000765): Train loss 0.122, Val loss 0.125\n",
            "Ep 1 (Step 000770): Train loss 0.120, Val loss 0.124\n",
            "Ep 1 (Step 000775): Train loss 0.121, Val loss 0.123\n",
            "Ep 1 (Step 000780): Train loss 0.121, Val loss 0.123\n",
            "Ep 1 (Step 000785): Train loss 0.119, Val loss 0.123\n",
            "Ep 1 (Step 000790): Train loss 0.121, Val loss 0.124\n",
            "Ep 1 (Step 000795): Train loss 0.123, Val loss 0.125\n",
            "Ep 1 (Step 000800): Train loss 0.123, Val loss 0.123\n",
            "Ep 1 (Step 000805): Train loss 0.120, Val loss 0.123\n",
            "Ep 1 (Step 000810): Train loss 0.126, Val loss 0.125\n",
            "Ep 1 (Step 000815): Train loss 0.123, Val loss 0.126\n",
            "Ep 1 (Step 000820): Train loss 0.125, Val loss 0.125\n",
            "Ep 1 (Step 000825): Train loss 0.124, Val loss 0.126\n",
            "Ep 1 (Step 000830): Train loss 0.117, Val loss 0.122\n",
            "Ep 1 (Step 000835): Train loss 0.121, Val loss 0.122\n",
            "Ep 1 (Step 000840): Train loss 0.124, Val loss 0.124\n",
            "Ep 1 (Step 000845): Train loss 0.120, Val loss 0.122\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Recommend the appropriate medical specialty and urgency based on the user symptoms.  ### Input: Symptoms: pregnancy nausea; Duration: 1-2 days; Age: 16; Sex: female; Comorbidities: none.  ### Response: Specialty: Obstetrics. Urgency: urgent.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Recommend the appropriate medical specialty and\n",
            "Training completed in 5.16 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path\n",
        "MODEL_NAME = \"med_model_1.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save the model state dict\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uFegQIg0RH8",
        "outputId": "0b8d18bf-2828-47a8-80b2-e2d641f46dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/med_model_1.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UcGvJprF1TJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}